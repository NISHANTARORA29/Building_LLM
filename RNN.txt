
Grad clip: combats exploding gradients, tying back to the original RNN pathology.

Weight tying: decoder weight = embedding weight (optional but useful on small corpora).


Decoder (self.decoder): 
ğ‘¦
ğ‘¡
=
ğ‘Š
ğ‘¦
â„
ğ‘¡
+
ğ‘
ğ‘¦
y
t
	â€‹

=W
y
	â€‹

h
t
	â€‹

+b
y
	â€‹

 â†’ loss uses cross-entropy over the vocab.

Grad clip: combats exploding gradients, tying back to the original RNN pathology.

Weight tying: decoder weight = embedding weight (optional but useful on small corpora).